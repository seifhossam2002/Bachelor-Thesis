{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdXLOGmPPwcG"
      },
      "source": [
        "Import files from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmC2KhL2Pvzu",
        "outputId": "150732a8-e273-4b1a-8fe7-d564ac9855d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww4O-M1A5QtI",
        "outputId": "e4835f26-dc1d-4f32-baf0-3515b703711d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: COLAB_GPU_TIMEOUT=24\n"
          ]
        }
      ],
      "source": [
        "%set_env COLAB_GPU_TIMEOUT=24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM-JGKNLPlK9"
      },
      "source": [
        "Args init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwdJFOLqPlLF"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "args = Args(\n",
        "    row_triples='/content/drive/MyDrive/Bachelor/FB15k/train.txt',\n",
        "    amie_plus_path='/content/drive/MyDrive/Bachelor/amie-milestone-intKB.jar',\n",
        "    minpca='0.5',\n",
        "    minc='0.8',\n",
        "    minhc='0.1',\n",
        "#     new_prediction_path='./kaggle/working/new_prediction.tsv',\n",
        "    new_prediction_path='/content/drive/MyDrive/Bachelor/Results/new_triple.txt',\n",
        "\n",
        "\n",
        "    do_train=True,\n",
        "    do_valid = True,\n",
        "    do_test = True,\n",
        "    evaluate_train = True,\n",
        "    data_path='/content/drive/MyDrive/Bachelor/FB15k',\n",
        "    model='RotatE',\n",
        "    negative_sample_size=256,\n",
        "    batch_size=1024,\n",
        "    hidden_dim=1000,\n",
        "    gamma=24.0,\n",
        "    adversarial_temperature=1.0,\n",
        "    negative_adversarial_sampling=True,\n",
        "    learning_rate=0.0001,\n",
        "    margin = None,\n",
        "    max_steps=15000,\n",
        "    max_steps_per = 2000,\n",
        "    test_batch_size = 16,\n",
        "    save_path='/content/drive/MyDrive/Bachelor/Results',\n",
        "    double_entity_embedding=True,\n",
        "    double_relation_embedding=False,\n",
        "    countries=False,\n",
        "    cpu_num=8,\n",
        "    cuda=True,\n",
        "    warm_up_steps=None,\n",
        "    # init_checkpoint = '/content/drive/MyDrive/Bachelor/Results',\n",
        "    init_checkpoint = None,\n",
        "    uni_weight = False,\n",
        "    regularization = 0.00003,\n",
        "    # save_checkpoint_steps = 800,\n",
        "    save_checkpoint_steps = 2000,\n",
        "    log_steps = 100,\n",
        "    valid_steps = 200,\n",
        "    test_log_steps = 200,\n",
        "    sparsity = False,\n",
        "    conclusion_batch_size = 32,\n",
        "    use_rule = True,\n",
        "    NNE = True,\n",
        "    use_rule_coefficient = 0.0001\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2JvnIExPlLL"
      },
      "source": [
        "Rule Mining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrysvfvvPlLM"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "\n",
        "def m_n_s(args, tsv_source_path, amie_path, minhc=0.01, minc=None, minpca=None):\n",
        "    amie_arg = \"java -XX:-UseGCOverheadLimit -Xmx4G -jar \" + amie_path + \" \" + tsv_source_path\n",
        "\n",
        "    if minhc != 0.01 and minhc:\n",
        "        amie_arg += \" -minhc \"\n",
        "        amie_arg += str(minhc)\n",
        "    if minc:\n",
        "        amie_arg += \" -minc \"\n",
        "        amie_arg += str(minc)\n",
        "    if minpca:\n",
        "        amie_arg += \" -minpca \"\n",
        "        amie_arg += str(minpca)\n",
        "\n",
        "    output_directory = args.save_path\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    res_file = os.path.join(output_directory, 'result.txt')\n",
        "\n",
        "    # tsv_target_path = \"result_\" + tsv_source_path\n",
        "    open(res_file, 'w').close()     # clean up the old content in result.txt\n",
        "    amie_arg += \" >>\"+res_file\n",
        "    print(amie_arg)\n",
        "    # to run the command in the shell\n",
        "    os.system(amie_arg)\n",
        "    print(\"AMIE Done\")\n",
        "\n",
        "    cols = [[] for x in range(11)]\n",
        "    total_mined_rules = 0\n",
        "    with open(res_file, 'r') as source:\n",
        "        for line in source:\n",
        "            if line[0] == '?':\n",
        "                total_mined_rules += 1\n",
        "                current_line = line.split()\n",
        "                # print(current_line)\n",
        "                if len(current_line) != 0:\n",
        "                    current_rule = ''\n",
        "                    if len(current_line) == 17:\n",
        "                        for i in range(0, 10):\n",
        "                            current_rule = current_rule + current_line[i] + ' '\n",
        "                        cols[0].append(current_rule)\n",
        "\n",
        "                        for j in range(10, 17):\n",
        "                            if current_line[j][0] != '?':\n",
        "                                cols[j - 9].append(float(current_line[j]))\n",
        "                            else:\n",
        "                                cols[j - 9].append(current_line[j])\n",
        "                    else:\n",
        "                        for i in range(0, 7):\n",
        "                            current_rule = current_rule + current_line[i] + ' '\n",
        "                        cols[0].append(current_rule)\n",
        "\n",
        "                        for j in range(7, 14):\n",
        "                            if current_line[j][0] != '?':\n",
        "                                cols[j - 6].append(float(current_line[j]))\n",
        "                            else:\n",
        "                                cols[j - 6].append(current_line[j])\n",
        "\n",
        "    df = pandas.DataFrame({\n",
        "            'rule': cols[0],\n",
        "            'v1': cols[1],\n",
        "            'v2': cols[2],\n",
        "            'v3': cols[3],\n",
        "            'v4': cols[4],\n",
        "            'v5': cols[5],\n",
        "            'v6': cols[6],\n",
        "            'v7': cols[7]\n",
        "        })\n",
        "\n",
        "    current_dir = os.path.abspath(os.path.dirname(\"__file__\"))\n",
        "\n",
        "    pca_sorted_path = os.path.join(current_dir, \"pca_sorted_rule.tsv\")\n",
        "    std_sorted_path = os.path.join(current_dir, \"std_sorted_rule.tsv\")\n",
        "    sorted_by_pca = df.sort_values(by='v3', ascending=False)\n",
        "    sorted_by_std = df.sort_values(by='v2', ascending=False)\n",
        "    sorted_by_pca.to_csv(pca_sorted_path, sep='\\t', header=False, index= False)\n",
        "    sorted_by_std.to_csv(std_sorted_path, sep='\\t')\n",
        "\n",
        "#     rules_df = df[['rule', 'v3']]\n",
        "\n",
        "    # Saving the DataFrame to a file named \"Rules.csv\"\n",
        "#     rules_df.to_csv('/kaggle/working/Rules.tsv', sep='\\t', index=False, header=False)\n",
        "\n",
        "#     return pca_sorted_path, std_sorted_path, total_mined_rules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCWYPruHPlLQ"
      },
      "source": [
        "Preprocess file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0OKR5I3PlLR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def rule_transform(rule):\n",
        "    rule_body, rule_head = rule.split('=>')\n",
        "    rule_head = rule_head[5:-4]\n",
        "\n",
        "    mark = ''\n",
        "\n",
        "    if '?h' in rule_body:\n",
        "        mark = '?h'\n",
        "\n",
        "    if '?g' in rule_body:\n",
        "        mark = '?g'\n",
        "\n",
        "    if '?f' in rule_body:\n",
        "        mark = '?f'\n",
        "\n",
        "    if '?e' in rule_body:\n",
        "        mark = '?e'\n",
        "\n",
        "    if '?f' in rule_body:\n",
        "        mark = '?f'\n",
        "\n",
        "\n",
        "    if len(mark) > 0:\n",
        "        r1 = ''\n",
        "        r2 = ''\n",
        "        rule_body_list = rule_body.split('  ')[:-1]\n",
        "\n",
        "        ni_r1_qian = rule_body_list[0] == mark and rule_body_list[2] == '?a'\n",
        "        shun_r1_qian = rule_body_list[0] == '?a' and rule_body_list[2] == mark\n",
        "        ni_r1_hou =rule_body_list[3] == mark and rule_body_list[5] == '?a'\n",
        "        shun_r1_hou = rule_body_list[3] == '?a' and rule_body_list[5] == mark\n",
        "\n",
        "        ni_r2_qian = rule_body_list[0] == '?b' and rule_body_list[2] == mark\n",
        "        shun_r2_qian = rule_body_list[0] == mark and rule_body_list[2] == '?b'\n",
        "        ni_r2_hou = rule_body_list[3] == '?b' and rule_body_list[5] == mark\n",
        "        shun_r2_hou = rule_body_list[3] == mark and rule_body_list[5] == '?b'\n",
        "\n",
        "        if ni_r2_qian and shun_r1_hou:\n",
        "            r2 = '-' + rule_body_list[1]\n",
        "            r1 = rule_body_list[4]\n",
        "        elif shun_r2_qian and shun_r1_hou:\n",
        "            r2 = rule_body_list[1]\n",
        "            r1 = rule_body_list[4]\n",
        "        elif ni_r2_hou and shun_r1_qian:\n",
        "            r2 = '-' + rule_body_list[4]\n",
        "            r1 = rule_body_list[1]\n",
        "        elif shun_r2_hou and shun_r1_qian:\n",
        "            r2 = rule_body_list[4]\n",
        "            r1 = rule_body_list[1]\n",
        "        elif ni_r1_hou and ni_r2_qian:\n",
        "            r1 = '-' + rule_body_list[4]\n",
        "            r2 = '-' + rule_body_list[1]\n",
        "        elif ni_r1_hou and shun_r2_qian:\n",
        "            r1 = '-' + rule_body_list[4]\n",
        "            r2 = rule_body_list[1]\n",
        "        elif ni_r1_qian and ni_r2_hou:\n",
        "            r2 = '-' + rule_body_list[4]\n",
        "            r1 = '-' + rule_body_list[1]\n",
        "        elif ni_r1_qian and shun_r2_hou:\n",
        "            r1 = '-' + rule_body_list[1]\n",
        "            r2 = rule_body_list[4]\n",
        "\n",
        "        return r1 + ',' + r2 + ',' + rule_head\n",
        "\n",
        "    else:\n",
        "        rule_body_list = rule_body.split('  ')[:-1]\n",
        "        if len(rule_body.split('  ')) >= 7:\n",
        "            ni__qian = rule_body_list[0] == '?b' and rule_body_list[2] == '?a'\n",
        "            shun__qian = rule_body_list[0] == '?a' and rule_body_list[2] == '?b'\n",
        "            ni__hou = rule_body_list[3] == '?b' and rule_body_list[5] == '?a'\n",
        "            shun__hou = rule_body_list[3] == '?a' and rule_body_list[5] == '?b'\n",
        "            if ni__qian and shun__hou:\n",
        "                r2 = rule_body_list[1]\n",
        "                r1 = rule_body_list[4]\n",
        "            elif shun__qian and shun__hou:\n",
        "                r1 = rule_body_list[1]\n",
        "                r2 = '-' + rule_body_list[4]\n",
        "            elif ni__hou and shun__qian:\n",
        "                r2 = rule_body_list[4]\n",
        "                r1 = rule_body_list[1]\n",
        "            elif ni__hou and ni__qian:\n",
        "                r2 = rule_body_list[4]\n",
        "                r1 = '-' + rule_body_list[1]\n",
        "            return r1 + ',' + r2 + ',' + rule_head\n",
        "        else:\n",
        "            if rule_body[:2] == '?a':\n",
        "                return rule_body[4:-7] + ',' + rule_head\n",
        "            elif rule_body[:2] == '?b':\n",
        "                return '-' + rule_body[4:-7] + ',' + rule_head\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess():\n",
        "\n",
        "    rule_file = os.path.join(args.save_path, 'result.txt')\n",
        "    rule_file2 = os.path.join(args.save_path, 'Rules.txt')\n",
        "\n",
        "    with open(rule_file, 'r') as f:\n",
        "        with open(rule_file2, 'w') as f2:\n",
        "            for line in f:\n",
        "                # if it begins with ?\n",
        "                if line[0] != '?':\n",
        "                    continue\n",
        "                Rule, Head_Coverage, Std_Confidence, PCA_Confidence, Positive_Examples, Body_size, PCA_Body_size, _ \\\n",
        "                    = line.strip().split('\\t')\n",
        "\n",
        "                # Rule, PCA_Confidence  = line.strip().split('\\t')\n",
        "\n",
        "                rule_str = rule_transform(Rule)\n",
        "                newline = rule_str + '\\t' + str(PCA_Confidence) + '\\n'\n",
        "\n",
        "                f2.write(newline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMVLPf2QPlLU"
      },
      "source": [
        "Rule Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqHhFqbXPlLV"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def one_time_reasoning_for_dense(entity, rules, new_tri, in_map, out_map):\n",
        "    for rule_index, (rule, p) in enumerate(rules):\n",
        "        if len(rule) == 3:\n",
        "            if rule[0].startswith('-'):\n",
        "                e2_list = in_map[(rule[0][1:], entity)]\n",
        "            else:\n",
        "                e2_list = out_map[(entity, rule[0])]\n",
        "\n",
        "            if len(e2_list) > 0:\n",
        "                for e2 in e2_list:\n",
        "                    if rule[1].startswith('-'):\n",
        "                        e3_list = in_map[(rule[1][1:], e2)]\n",
        "                    else:\n",
        "                        e3_list = out_map[(e2, rule[1])]\n",
        "                    for e3 in e3_list:\n",
        "                        new_tri.add((entity, rule[2], e3))\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "\n",
        "        elif len(rule) == 2:\n",
        "\n",
        "            if rule[0].startswith('-'):\n",
        "                e2_list = in_map[(rule[0][1:], entity)]\n",
        "            else:\n",
        "                e2_list = out_map[(entity, rule[0])]\n",
        "\n",
        "            for e2 in e2_list:\n",
        "                new_tri.add((entity, rule[1], e2))\n",
        "\n",
        "\n",
        "def one_time_reasoning(entity, rules, new_tri, in_map, out_map):\n",
        "    for e1 in entity:\n",
        "        for rule_index, (rule, p) in enumerate(rules):\n",
        "            if len(rule) == 3:\n",
        "                if rule[0].startswith('-'):\n",
        "                    e2_list = in_map[(rule[0][1:], e1)]\n",
        "                else:\n",
        "                    e2_list = out_map[(e1, rule[0])]\n",
        "\n",
        "                if len(e2_list) > 0:\n",
        "                    for e2 in e2_list:\n",
        "                        if rule[1].startswith('-'):\n",
        "                            e3_list = in_map[(rule[1][1:], e2)]\n",
        "                        else:\n",
        "                            e3_list = out_map[(e2, rule[1])]\n",
        "                        for e3 in e3_list:\n",
        "                            new_tri.add((e1, rule[2], e3, p))\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "\n",
        "            elif len(rule) == 2:\n",
        "\n",
        "                if rule[0].startswith('-'):\n",
        "                    e2_list = in_map[(rule[0][1:], e1)]\n",
        "                else:\n",
        "                    e2_list = out_map[(e1, rule[0])]\n",
        "\n",
        "                for e2 in e2_list:\n",
        "                    new_tri.add((e1, rule[1], e2, p))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dense_your_graph(input, rules):\n",
        "    new_triples = set()\n",
        "    out_map = defaultdict(list)\n",
        "    in_map = defaultdict(list)\n",
        "    entity = set()\n",
        "\n",
        "    with open(input, 'r', encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            e1, r, e2 = line.strip().split(\"\\t\")\n",
        "            out_map[(e1, r)].append(e2)\n",
        "            in_map[(r, e2)].append(e1)\n",
        "            entity.add(e1)\n",
        "            entity.add(e2)\n",
        "\n",
        "    entity = list(entity)\n",
        "\n",
        "    for i in entity:\n",
        "        one_time_reasoning_for_dense(i, rules, new_triples, in_map, out_map)\n",
        "\n",
        "    return new_triples\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "def rule_reasoning(args):\n",
        "\n",
        "    input_tri = args.row_triples\n",
        "\n",
        "    train_set = set()\n",
        "\n",
        "    with open(input_tri) as f_train:\n",
        "        for line in f_train:\n",
        "            h, r, t = line.strip().split('\\t')\n",
        "            train_set.add((h, r, t))\n",
        "\n",
        "\n",
        "    out_new_triples = args.new_prediction_path\n",
        "    rules_path = os.path.join(args.save_path, 'Rules.txt')\n",
        "\n",
        "    rules = []\n",
        "\n",
        "    with open(rules_path, 'r', encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            rule, p = line.strip().split('\\t')\n",
        "            rules.append(tuple([tuple(rule.split(',')), float(p)]))\n",
        "\n",
        "    f_out = open(out_new_triples, 'w')\n",
        "\n",
        "    for i in range(len(rules)):\n",
        "\n",
        "        newline = ''\n",
        "        rules2 = rules[i:i + 1]\n",
        "        _, p = rules2[0]\n",
        "        newline += str(p) + '\\t'\n",
        "        new_triples = dense_your_graph(input_tri, rules2)\n",
        "        new_triples = new_triples - train_set\n",
        "\n",
        "\n",
        "        for h, r, t in new_triples:\n",
        "            newline += h + '@$' + r + '@$' + t + '\\t'\n",
        "        newline = newline[:-1] + '\\n'\n",
        "\n",
        "        if len(new_triples) > 0:\n",
        "            f_out.write(newline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSS-4cr-PlLY"
      },
      "source": [
        "Run file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kxIbQfpPlLa"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python3\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "def parse_args(args=None):\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Training and Testing Knowledge Graph Embedding Models',\n",
        "        usage='train.py [<args>] [-h | --help]'\n",
        "    )\n",
        "\n",
        "    parser.add_argument('--cuda', action='store_true', help='use GPU')\n",
        "\n",
        "    parser.add_argument('-ur', '--use_rule', action='store_true')\n",
        "    parser.add_argument('-urc', '--use_rule_coefficient', default=0.0001, type=float)\n",
        "    parser.add_argument('--sparsity', action='store_true')\n",
        "    parser.add_argument('--NNE', action='store_true')\n",
        "    parser.add_argument('-cbs', '--conclusion_batch_size', default=32, type=int)\n",
        "    parser.add_argument(\"--max_steps_per\", default=40000, type=int)\n",
        "\n",
        "    parser.add_argument('--do_train', action='store_true')\n",
        "    parser.add_argument('--do_valid', action='store_true')\n",
        "    parser.add_argument('--do_test', action='store_true')\n",
        "    parser.add_argument('--evaluate_train', action='store_true', help='Evaluate on training data')\n",
        "\n",
        "    parser.add_argument('--countries', action='store_true', help='Use Countries S1/S2/S3 datasets')\n",
        "    parser.add_argument('--regions', type=int, nargs='+', default=None,\n",
        "                        help='Region Id for Countries S1/S2/S3 datasets, DO NOT MANUALLY SET')\n",
        "\n",
        "    parser.add_argument('--data_path', type=str, default=None)\n",
        "    parser.add_argument('--model', default='TransE', type=str)\n",
        "    parser.add_argument('-de', '--double_entity_embedding', action='store_true')\n",
        "    parser.add_argument('-dr', '--double_relation_embedding', action='store_true')\n",
        "\n",
        "\n",
        "\n",
        "    parser.add_argument('-n', '--negative_sample_size', default=128, type=int)\n",
        "    parser.add_argument('-d', '--hidden_dim', default=500, type=int)\n",
        "    parser.add_argument('-g', '--gamma', default=12.0, type=float)\n",
        "    parser.add_argument('-adv', '--negative_adversarial_sampling', action='store_true')\n",
        "    parser.add_argument('-a', '--adversarial_temperature', default=1.0, type=float)\n",
        "    parser.add_argument('-b', '--batch_size', default=1024, type=int)\n",
        "    parser.add_argument('-r', '--regularization', default=0.0, type=float)\n",
        "    parser.add_argument('--test_batch_size', default=4, type=int, help='valid/test batch size')\n",
        "    parser.add_argument('--uni_weight', action='store_true',\n",
        "                        help='Otherwise use subsampling weighting like in word2vec')\n",
        "\n",
        "    parser.add_argument('-lr', '--learning_rate', default=0.0001, type=float)\n",
        "    parser.add_argument('-cpu', '--cpu_num', default=10, type=int)\n",
        "    parser.add_argument('-init', '--init_checkpoint', default=None, type=str)\n",
        "    parser.add_argument('-save', '--save_path', default=None, type=str)\n",
        "    parser.add_argument('--max_steps', default=300000, type=int)\n",
        "    parser.add_argument('--warm_up_steps', default=None, type=int)\n",
        "\n",
        "    parser.add_argument('--save_checkpoint_steps', default=10000, type=int)\n",
        "    parser.add_argument('--valid_steps', default=10000, type=int)\n",
        "    parser.add_argument('--log_steps', default=100, type=int, help='train log every xx steps')\n",
        "    parser.add_argument('--test_log_steps', default=1000, type=int, help='valid/test log every xx steps')\n",
        "\n",
        "    parser.add_argument('--nentity', type=int, default=0, help='DO NOT MANUALLY SET')\n",
        "    parser.add_argument('--nrelation', type=int, default=0, help='DO NOT MANUALLY SET')\n",
        "\n",
        "    return parser.parse_args(args)\n",
        "\n",
        "def override_config(args):\n",
        "    '''\n",
        "    Override model and data configuration\n",
        "    '''\n",
        "\n",
        "    with open(os.path.join(args.init_checkpoint, 'config.json'), 'r') as fjson:\n",
        "        argparse_dict = json.load(fjson)\n",
        "\n",
        "    args.countries = argparse_dict['countries']\n",
        "    if args.data_path is None:\n",
        "        args.data_path = argparse_dict['data_path']\n",
        "    args.model = argparse_dict['model']\n",
        "    args.double_entity_embedding = argparse_dict['double_entity_embedding']\n",
        "    args.double_relation_embedding = argparse_dict['double_relation_embedding']\n",
        "    args.hidden_dim = argparse_dict['hidden_dim']\n",
        "    args.test_batch_size = argparse_dict['test_batch_size']\n",
        "\n",
        "\n",
        "def save_model(model, optimizer, save_variable_list, args):\n",
        "    '''\n",
        "    Save the parameters of the model and the optimizer,\n",
        "    as well as some other variables such as step and learning_rate\n",
        "    '''\n",
        "\n",
        "    argparse_dict = vars(args)\n",
        "    with open(os.path.join(args.save_path, 'config.json'), 'w') as fjson:\n",
        "        json.dump(argparse_dict, fjson)\n",
        "\n",
        "    print(\"My variable list: \", save_variable_list)\n",
        "\n",
        "    torch.save({\n",
        "        **save_variable_list,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()},\n",
        "        os.path.join(args.save_path, 'checkpoint')\n",
        "    )\n",
        "\n",
        "    entity_embedding = model.entity_embedding.detach().cpu().numpy()\n",
        "    np.save(\n",
        "        os.path.join(args.save_path, 'entity_embedding'),\n",
        "        entity_embedding\n",
        "    )\n",
        "\n",
        "    relation_embedding = model.relation_embedding.detach().cpu().numpy()\n",
        "    np.save(\n",
        "        os.path.join(args.save_path, 'relation_embedding'),\n",
        "        relation_embedding\n",
        "    )\n",
        "\n",
        "def read_triple(file_path, entity2id, relation2id):\n",
        "    '''\n",
        "    Read triples and map them into ids.\n",
        "    '''\n",
        "    triples = []\n",
        "    with open(file_path) as fin:\n",
        "        for line in fin:\n",
        "            h, r, t = line.strip().split('\\t')\n",
        "            triples.append((entity2id[h], relation2id[r], entity2id[t]))\n",
        "    return triples\n",
        "\n",
        "def read_triple2(file_path, entity2id, relation2id):\n",
        "    '''\n",
        "    Read triples and map them into ids.\n",
        "    '''\n",
        "    triples = []\n",
        "    with open(file_path) as fin:\n",
        "        for line in fin:\n",
        "            h, t, r = line.strip().split('\\t')\n",
        "            triples.append((entity2id[h], relation2id[r], entity2id[t]))\n",
        "    return triples\n",
        "\n",
        "def set_logger(args):\n",
        "    '''\n",
        "    Write logs to checkpoint and console\n",
        "    '''\n",
        "\n",
        "    if args.do_train:\n",
        "        log_file = os.path.join(args.save_path or args.init_checkpoint, 'train.log')\n",
        "    else:\n",
        "        log_file = os.path.join(args.save_path or args.init_checkpoint, 'test.log')\n",
        "# hello\n",
        "    logging.basicConfig(\n",
        "        format='%(asctime)s %(levelname)-8s %(message)s',\n",
        "        datefmt='%Y-%m-%d %H:%M:%S',\n",
        "        filename=log_file,\n",
        "        filemode='w'\n",
        "    )\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.CRITICAL)\n",
        "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
        "    console.setFormatter(formatter)\n",
        "    logging.getLogger('').addHandler(console)\n",
        "\n",
        "def log_metrics(mode, step, metrics):\n",
        "    '''\n",
        "    Print the evaluation logs\n",
        "    '''\n",
        "    for metric in metrics:\n",
        "        if metric == 'rule triple score:':\n",
        "            logging.critical('%s %s at step %d: \\n %s' % (mode, metric, step, str(metrics[metric])))\n",
        "        else:\n",
        "            logging.critical('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))\n",
        "\n",
        "\n",
        "def runKGE(args):\n",
        "    if (not args.do_train) and (not args.do_valid) and (not args.do_test):\n",
        "        raise ValueError('one of train/val/test mode must be choosed.')\n",
        "\n",
        "    if args.init_checkpoint:\n",
        "        override_config(args)\n",
        "    elif args.data_path is None:\n",
        "        raise ValueError('one of init_checkpoint/data_path must be choosed.')\n",
        "\n",
        "    if args.do_train and args.save_path is None:\n",
        "        raise ValueError('Where do you want to save your trained model?')\n",
        "\n",
        "    if args.save_path and not os.path.exists(args.save_path):\n",
        "        os.makedirs(args.save_path)\n",
        "\n",
        "    # Write logs to checkpoint and console\n",
        "    set_logger(args)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    rules_path = os.path.join(args.save_path, 'Rules.txt')\n",
        "#     rules_path = '/kaggle/input/myoutput/Rules.txt'\n",
        "    rules = []\n",
        "    with open(rules_path, 'r', encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            rule, p = line.strip().split('\\t')\n",
        "            rules.append(tuple([tuple(rule.split(',')), float(p)]))\n",
        "\n",
        "\n",
        "    with open(os.path.join(args.data_path, 'entities.dict')) as fin:\n",
        "        entity2id = dict()\n",
        "        id2entity = dict()\n",
        "        for line in fin:\n",
        "            eid, entity = line.strip().split('\\t')\n",
        "            entity2id[entity] = int(eid)\n",
        "            id2entity[int(eid)] = entity\n",
        "\n",
        "    with open(os.path.join(args.data_path, 'relations.dict')) as fin:\n",
        "        relation2id = dict()\n",
        "        id2relation = dict()\n",
        "        for line in fin:\n",
        "            rid, relation = line.strip().split('\\t')\n",
        "            relation2id[relation] = int(rid)\n",
        "            id2relation[int(rid)] = relation\n",
        "\n",
        "    # Read regions for Countries S* datasets\n",
        "    if args.countries:\n",
        "        regions = list()\n",
        "        with open(os.path.join(args.data_path, 'regions.list')) as fin:\n",
        "            for line in fin:\n",
        "                region = line.strip()\n",
        "                regions.append(entity2id[region])\n",
        "        args.regions = regions\n",
        "\n",
        "    nentity = len(entity2id)\n",
        "    nrelation = len(relation2id)\n",
        "\n",
        "    args.nentity = nentity\n",
        "    args.nrelation = nrelation\n",
        "    print('Model', args.model)\n",
        "    logging.critical('Model: %s' % args.model)\n",
        "    logging.critical('Data Path: %s' % args.data_path)\n",
        "    logging.critical('#entity: %d' % nentity)\n",
        "    logging.critical('#relation: %d' % nrelation)\n",
        "\n",
        "    train_triples = read_triple(os.path.join(args.data_path, 'train.txt'), entity2id, relation2id)\n",
        "    logging.critical('#train: %d' % len(train_triples))\n",
        "    valid_triples = read_triple(os.path.join(args.data_path, 'valid.txt'), entity2id, relation2id)\n",
        "\n",
        "    logging.critical('#valid: %d' % len(valid_triples))\n",
        "    test_triples = read_triple(os.path.join(args.data_path, 'test.txt'), entity2id, relation2id)\n",
        "    logging.critical('#test: %d' % len(test_triples))\n",
        "\n",
        "    #All true triples\n",
        "    all_true_triples = train_triples + valid_triples + test_triples\n",
        "    if args.sparsity:\n",
        "        sparse_triples = read_triple2(os.path.join(args.data_path, 'test_sparsity_0.995.txt'), entity2id, relation2id)\n",
        "        all_true_triples = train_triples + valid_triples + sparse_triples\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def conclusion_filtering(entity_embedding, relation_embedding, embedding_range, gamma, new_triple):\n",
        "\n",
        "        def RotatE_score(head, relation, tail):\n",
        "            pi = 3.14159265358979323846\n",
        "\n",
        "            re_head, im_head = torch.chunk(head, 2, dim=0)\n",
        "            re_tail, im_tail = torch.chunk(tail, 2, dim=0)\n",
        "\n",
        "            # Make phases of relations uniformly distributed in [-pi, pi]\n",
        "\n",
        "            phase_relation = relation / (embedding_range.item() / pi)\n",
        "\n",
        "            re_relation = torch.cos(phase_relation)\n",
        "            im_relation = torch.sin(phase_relation)\n",
        "\n",
        "            re_score = re_head * re_relation - im_head * im_relation\n",
        "            im_score = re_head * im_relation + im_head * re_relation\n",
        "            re_score = re_score - re_tail\n",
        "            im_score = im_score - im_tail\n",
        "\n",
        "            score = torch.stack([re_score, im_score], dim=0)\n",
        "            score = score.norm(dim=0)\n",
        "\n",
        "            score = gamma.item() - score.sum(dim=0)\n",
        "\n",
        "            # re_head, im_head = torch.chunk(head, 2, dim=0)\n",
        "            # re_relation, im_relation = torch.chunk(relation, 2, dim=0)\n",
        "\n",
        "            # re_tail, im_tail = torch.chunk(tail, 2, dim=0)\n",
        "            # re_score = re_head * re_relation - im_head * im_relation\n",
        "            # im_score = re_head * im_relation + im_head * re_relation\n",
        "            # score = re_score * re_tail + im_score * im_tail\n",
        "            # score = score.sum(dim=0)\n",
        "            return score\n",
        "        true_conclusions = []\n",
        "        for h,r,t in new_triple:\n",
        "            head, relation, tail = entity_embedding[h], relation_embedding[r], entity_embedding[t]\n",
        "            if torch.sigmoid(RotatE_score(head, relation, tail)) > 0.99:\n",
        "                true_conclusions.append((h,r,t))\n",
        "        return true_conclusions\n",
        "\n",
        "    def more_triple_p(new_triple_path):\n",
        "        rule_num = 0\n",
        "        rule_triples_index = []\n",
        "        new_triple_only = []\n",
        "        with open(new_triple_path) as f:\n",
        "            for line in f:\n",
        "                rule_num += 1\n",
        "                rule_triples = line.strip().split('\\t')\n",
        "                p = float(rule_triples[0])\n",
        "                rule_triples = rule_triples[1:]\n",
        "\n",
        "                for i in rule_triples:\n",
        "                    # h, r, t = i.split(' ')\n",
        "                    h, r, t = i.split('@$')\n",
        "\n",
        "                    rule_triples_index.append((entity2id[h], relation2id[r], entity2id[t], p))\n",
        "                    new_triple_only.append((entity2id[h], relation2id[r], entity2id[t]))\n",
        "\n",
        "        return rule_triples_index, new_triple_only,rule_num\n",
        "\n",
        "\n",
        "    new_triple, new_triple_only,rule_num = more_triple_p(args.new_prediction_path)\n",
        "#     new_triple, new_triple_only,rule_num = more_triple_p('/kaggle/input/myoutput/new_triple.txt')\n",
        "\n",
        "\n",
        "\n",
        "    kge_model = KGEModel(\n",
        "        model_name=args.model,\n",
        "        nentity=nentity,\n",
        "        nrelation=nrelation,\n",
        "        hidden_dim=args.hidden_dim,\n",
        "        gamma=args.gamma,\n",
        "        double_entity_embedding=args.double_entity_embedding,\n",
        "        double_relation_embedding=args.double_relation_embedding\n",
        "    )\n",
        "\n",
        "    logging.critical('Model Parameter Configuration:')\n",
        "    for name, param in kge_model.named_parameters():\n",
        "        logging.critical('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
        "\n",
        "    if args.cuda:\n",
        "        kge_model = kge_model.cuda()\n",
        "\n",
        "    if args.do_train:\n",
        "        # Set training dataloader iterator\n",
        "        train_dataloader_head = DataLoader(\n",
        "            TrainDataset(train_triples,new_triple_only, nentity, nrelation, args.negative_sample_size, 'head-batch'),\n",
        "            batch_size=args.batch_size,\n",
        "            shuffle=True,\n",
        "            # num_workers=max(1, args.cpu_num//2),\n",
        "            num_workers=1,\n",
        "            collate_fn=TrainDataset.collate_fn\n",
        "        )\n",
        "\n",
        "        train_dataloader_tail = DataLoader(\n",
        "            TrainDataset(train_triples, new_triple_only,nentity,  nrelation, args.negative_sample_size, 'tail-batch'),\n",
        "            batch_size=args.batch_size,\n",
        "            shuffle=True,\n",
        "            # num_workers=max(1, args.cpu_num//2),\n",
        "            num_workers=1,\n",
        "            collate_fn=TrainDataset.collate_fn\n",
        "        )\n",
        "\n",
        "        train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)\n",
        "\n",
        "\n",
        "        train_rule_triple = DataLoader(\n",
        "            RuleTriple(new_triple, nentity, nrelation),\n",
        "            batch_size=args.conclusion_batch_size,\n",
        "            shuffle=True,\n",
        "            # num_workers=max(1, args.cpu_num//2),\n",
        "            num_workers=1,\n",
        "            collate_fn=RuleTriple.collate_fn\n",
        "        )\n",
        "\n",
        "        train_rule_triple_iterator = Iterator(train_rule_triple)\n",
        "\n",
        "\n",
        "\n",
        "        # Set training configuration\n",
        "        current_learning_rate = args.learning_rate\n",
        "        optimizer = torch.optim.Adam(\n",
        "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
        "            lr=current_learning_rate\n",
        "        )\n",
        "        if args.warm_up_steps:\n",
        "            warm_up_steps = args.warm_up_steps\n",
        "        else:\n",
        "            warm_up_steps = args.max_steps // 2\n",
        "\n",
        "    if args.init_checkpoint:\n",
        "        # Restore model from checkpoint directory\n",
        "        logging.critical('Loading checkpoint %s...' % args.init_checkpoint)\n",
        "        checkpoint = torch.load(os.path.join(args.init_checkpoint, 'checkpoint'))\n",
        "        init_step = checkpoint['step']\n",
        "        print(os.path.join(args.init_checkpoint, 'checkpoint')) #hello\n",
        "        kge_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        if args.do_train:\n",
        "            current_learning_rate = checkpoint['current_learning_rate']\n",
        "            warm_up_steps = checkpoint['warm_up_steps']\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    else:\n",
        "        logging.critical('Ramdomly Initializing %s Model...' % args.model)\n",
        "        init_step = 0\n",
        "\n",
        "    step = init_step\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    logging.critical('Start Training...')\n",
        "    logging.critical('init_step = %d' % init_step)\n",
        "    logging.critical('batch_size = %d' % args.batch_size)\n",
        "    logging.critical('negative_adversarial_sampling = %d' % args.negative_adversarial_sampling)\n",
        "    logging.critical('hidden_dim = %d' % args.hidden_dim)\n",
        "    logging.critical('gamma = %f' % args.gamma)\n",
        "    logging.critical('negative_adversarial_sampling = %s' % str(args.negative_adversarial_sampling))\n",
        "\n",
        "    if args.use_rule:\n",
        "        logging.critical('rule_num = %d' % rule_num)\n",
        "        logging.critical('new_triple_num = %d' % len(new_triple_only))\n",
        "\n",
        "    if args.negative_adversarial_sampling:\n",
        "        logging.critical('adversarial_temperature = %f' % args.adversarial_temperature)\n",
        "\n",
        "    # Set valid dataloader as it would be evaluated during training\n",
        "    best_hits1 = 0\n",
        "    patience = 5  # Number of epochs to wait for improvement before stopping\n",
        "    no_improvement_counter = 0\n",
        "\n",
        "    if args.do_train:\n",
        "        logging.critical('learning_rate = %f' % current_learning_rate)\n",
        "\n",
        "        training_logs = []\n",
        "\n",
        "        #Training Loop\n",
        "        for step in range(init_step, args.max_steps):\n",
        "\n",
        "            log = kge_model.train_step(kge_model, optimizer, train_iterator, train_rule_triple_iterator, args)\n",
        "\n",
        "            training_logs.append(log)\n",
        "\n",
        "            if step >= warm_up_steps:\n",
        "                current_learning_rate = current_learning_rate / 10\n",
        "                logging.critical('Change learning_rate to %f at step %d' % (current_learning_rate, step))\n",
        "                optimizer = torch.optim.Adam(\n",
        "                    filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
        "                    lr=current_learning_rate\n",
        "                )\n",
        "                warm_up_steps = warm_up_steps * 3\n",
        "\n",
        "            if step % args.save_checkpoint_steps == 0:\n",
        "                save_variable_list = {\n",
        "                    'step': step,\n",
        "                    'current_learning_rate': current_learning_rate,\n",
        "                    'warm_up_steps': warm_up_steps\n",
        "                }\n",
        "                save_model(kge_model, optimizer, save_variable_list, args)\n",
        "\n",
        "            if step % args.log_steps == 0:\n",
        "                metrics = {}\n",
        "                for metric in training_logs[0].keys():\n",
        "                    if metric != \"rule triple score:\":\n",
        "                        metrics[metric] = sum([log[metric] for log in training_logs])/len(training_logs)\n",
        "                log_metrics('Training average', step, metrics)\n",
        "                # training_logs = []\n",
        "\n",
        "            if step % 1000 == 0:\n",
        "                metrics = {}\n",
        "                for metric in training_logs[0].keys():\n",
        "                    if metric == \"rule triple score:\":\n",
        "                        metrics[metric] = training_logs[-1][metric]\n",
        "                log_metrics('Training average', step, metrics)\n",
        "                training_logs = []\n",
        "\n",
        "            if args.do_valid and step % args.valid_steps == 0 and step != 0:\n",
        "                logging.critical('Evaluating on Valid Dataset...')\n",
        "                metrics,_,__ = kge_model.test_step(kge_model, valid_triples, all_true_triples, args, id2entity, id2relation)\n",
        "                log_metrics('Valid', step, metrics)\n",
        "                print(metrics)\n",
        "                hits1 = metrics['HITS@1']\n",
        "                if hits1 > best_hits1:\n",
        "                  best_hits1 = hits1\n",
        "                  no_improvement_counter = 0\n",
        "                else:\n",
        "                  no_improvement_counter += 1\n",
        "\n",
        "                # Check early stopping condition\n",
        "                if no_improvement_counter >= patience:\n",
        "                    logging.critical(f'Hits@1 did not improve for {patience} epochs. Early stopping...')\n",
        "                    break\n",
        "\n",
        "\n",
        "            if step % args.max_steps_per == 0:\n",
        "                true_conclusions = conclusion_filtering(kge_model.entity_embedding.detach().cpu(),\n",
        "                                               kge_model.relation_embedding.detach().cpu(),kge_model.embedding_range, kge_model.gamma,\n",
        "                                               new_triple_only)\n",
        "                train_triples = train_triples + true_conclusions\n",
        "                train_dataloader_head = DataLoader(\n",
        "                    TrainDataset(train_triples, new_triple_only, nentity, nrelation, args.negative_sample_size,\n",
        "                                 'head-batch'),\n",
        "                    batch_size=args.batch_size,\n",
        "                    shuffle=True,\n",
        "                    num_workers=max(1, args.cpu_num // 2),\n",
        "                    collate_fn=TrainDataset.collate_fn\n",
        "                )\n",
        "                train_dataloader_tail = DataLoader(\n",
        "                    TrainDataset(train_triples, new_triple_only, nentity, nrelation, args.negative_sample_size,\n",
        "                                 'tail-batch'),\n",
        "                    batch_size=args.batch_size,\n",
        "                    shuffle=True,\n",
        "                    num_workers=max(1, args.cpu_num // 2),\n",
        "                    collate_fn=TrainDataset.collate_fn\n",
        "                )\n",
        "                train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)\n",
        "                out_map = defaultdict(list)\n",
        "                in_map = defaultdict(list)\n",
        "                entity = set()\n",
        "                for e1, r, e2 in train_triples:\n",
        "                    actual_e1 = id2entity[e1]\n",
        "                    actual_e2 = id2entity[e2]\n",
        "                    actual_r = id2relation[r]\n",
        "                    out_map[(actual_e1, actual_r)].append(actual_e2)\n",
        "                    in_map[(actual_r, actual_e2)].append(actual_e1)\n",
        "                    entity.add(actual_e1)\n",
        "                    entity.add(actual_e2)\n",
        "                    # out_map[(e1, r)].append(e2)\n",
        "                    # in_map[(r, e2)].append(e1)\n",
        "                    # entity.add(e1)\n",
        "                    # entity.add(e2)\n",
        "                entity = list(entity)\n",
        "                conclusions = set()\n",
        "                one_time_reasoning(entity, rules, conclusions, in_map, out_map)\n",
        "                conclusions_list = list(conclusions)\n",
        "                for i in range(len(conclusions_list)):\n",
        "                    h, r, t, p = conclusions_list[i]\n",
        "                    conclusions_list[i] = (entity2id[h], relation2id[r], entity2id[t], p)\n",
        "\n",
        "#                 conclusions_list_filtered = []\n",
        "\n",
        "#                 for triple in conclusions_list:\n",
        "#                     triple_indices = triple[:3]\n",
        "#                     if triple_indices not in train_triples:\n",
        "#                         conclusions_list_filtered.append(triple)\n",
        "\n",
        "\n",
        "                train_rule_triple = DataLoader(\n",
        "                    RuleTriple(conclusions_list, nentity, nrelation),\n",
        "                    batch_size=args.conclusion_batch_size,\n",
        "                    shuffle=True,\n",
        "                    num_workers=max(1, args.cpu_num // 2),\n",
        "                    collate_fn=RuleTriple.collate_fn\n",
        "                )\n",
        "                train_rule_triple_iterator = Iterator(train_rule_triple)\n",
        "\n",
        "        save_variable_list = {\n",
        "            'step': step,\n",
        "            'current_learning_rate': current_learning_rate,\n",
        "            'warm_up_steps': warm_up_steps\n",
        "        }\n",
        "        save_model(kge_model, optimizer, save_variable_list, args)\n",
        "\n",
        "\n",
        "\n",
        "    if args.do_valid:\n",
        "        logging.critical('Evaluating on Valid Dataset...')\n",
        "        metrics, head_triple, tail_triple = kge_model.test_step(kge_model, valid_triples, all_true_triples, args, id2entity, id2relation)\n",
        "        log_metrics('Valid', step, metrics)\n",
        "\n",
        "    if args.sparsity:\n",
        "        logging.critical('Evaluating on sparsity Dataset...')\n",
        "        metrics, head_triple, tail_triple = kge_model.test_step(kge_model, sparse_triples, all_true_triples, args,id2entity, id2relation)\n",
        "        log_metrics('sparsity', step, metrics)\n",
        "\n",
        "    if args.do_test:\n",
        "        logging.critical('Evaluating on Test Dataset...')\n",
        "        metrics, head_triple, tail_triple = kge_model.test_step(kge_model, test_triples, all_true_triples, args, id2entity, id2relation)\n",
        "        log_metrics('Test', step, metrics)\n",
        "\n",
        "    if args.evaluate_train:\n",
        "        logging.critical('Evaluating on Training Dataset...')\n",
        "        metrics,head_triple, tail_triple = kge_model.test_step(kge_model, train_triples, all_true_triples, args, id2entity, id2relation)\n",
        "        log_metrics('Test', step, metrics)\n",
        "\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main(parse_args())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GHP11m4PlLh"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9wCxd7wPlLj"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python3\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class KGEModel(nn.Module):\n",
        "    def __init__(self, model_name, nentity, nrelation, hidden_dim, gamma,\n",
        "                 double_entity_embedding=False, double_relation_embedding=False, e_emb=None, et_emb=None, r_emb=None):\n",
        "        super(KGEModel, self).__init__()\n",
        "        self.model_name = model_name\n",
        "        self.nentity = nentity\n",
        "        self.nrelation = nrelation\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.epsilon = 2.0\n",
        "\n",
        "        self.gamma = nn.Parameter(\n",
        "            torch.Tensor([gamma]),\n",
        "            requires_grad=False\n",
        "        )\n",
        "\n",
        "        self.embedding_range = nn.Parameter(\n",
        "            torch.Tensor([(self.gamma.item() + self.epsilon) / hidden_dim]),\n",
        "            requires_grad=False\n",
        "        )\n",
        "\n",
        "        self.entity_dim = hidden_dim * 2 if double_entity_embedding else hidden_dim\n",
        "        self.relation_dim = hidden_dim * 2 if double_relation_embedding else hidden_dim\n",
        "\n",
        "\n",
        "        self.entity_embedding = nn.Parameter(torch.zeros(nentity, self.entity_dim))\n",
        "        nn.init.uniform_(\n",
        "            tensor=self.entity_embedding,\n",
        "            a=-self.embedding_range.item(),\n",
        "            b=self.embedding_range.item()\n",
        "        )\n",
        "\n",
        "        self.relation_embedding = nn.Parameter(torch.zeros(nrelation, self.relation_dim))\n",
        "        nn.init.uniform_(\n",
        "            tensor=self.relation_embedding,\n",
        "            a=-self.embedding_range.item(),\n",
        "            b=self.embedding_range.item()\n",
        "        )\n",
        "\n",
        "        # self.entity_embedding = nn.Parameter(e_emb, requires_grad=True)\n",
        "        # self.relation_embedding = nn.Parameter(r_emb, requires_grad=True)\n",
        "\n",
        "        # self.entity_dim = 400\n",
        "        # self.relation_dim = 200\n",
        "        # et_emb.requires_grad = True\n",
        "\n",
        "        # self.entity_embedding = nn.Parameter(torch.zeros(nentity, 400))\n",
        "        # nn.init.uniform_(\n",
        "        #     tensor=self.entity_embedding,\n",
        "        #     a=-self.embedding_range.item(),\n",
        "        #     b=self.embedding_range.item()\n",
        "        # )\n",
        "\n",
        "        # self.entity_embedding = nn.Parameter((self.entity_embedding + et_emb)/2)\n",
        "        #\n",
        "        # self.entity_embedding = nn.Parameter(e_emb, requires_grad=False)\n",
        "        # self.w = nn.Linear(800, 400)\n",
        "        # self.entity_embedding = nn.Parameter(self.w(torch.cat([self.entity_embedding, et_emb], dim=1)))\n",
        "        # self.relation_embedding = nn.Parameter(r_emb, requires_grad=True)\n",
        "\n",
        "        if model_name == 'pRotatE':\n",
        "            self.modulus = nn.Parameter(torch.Tensor([[0.5 * self.embedding_range.item()]]))\n",
        "\n",
        "        # Do not forget to modify this line when you add a new model in the \"forward\" function\n",
        "        if model_name not in ['TransE', 'DistMult', 'ComplEx', 'RotatE', 'pRotatE']:\n",
        "            raise ValueError('model %s not supported' % model_name)\n",
        "\n",
        "        if model_name == 'RotatE' and (not double_entity_embedding or double_relation_embedding):\n",
        "            raise ValueError('RotatE should use --double_entity_embedding')\n",
        "\n",
        "        if model_name == 'ComplEx' and (not double_entity_embedding or not double_relation_embedding):\n",
        "            raise ValueError('ComplEx should use --double_entity_embedding and --double_relation_embedding')\n",
        "\n",
        "    def forward(self, sample, mode='single'):\n",
        "        '''\n",
        "        Forward function that calculate the score of a batch of triples.\n",
        "        In the 'single' mode, sample is a batch of triple.\n",
        "        In the 'head-batch' or 'tail-batch' mode, sample consists two part.\n",
        "        The first part is usually the positive sample.\n",
        "        And the second part is the entities in the negative samples.\n",
        "        Because negative samples and positive samples usually share two elements\n",
        "        in their triple ((head, relation) or (relation, tail)).\n",
        "        '''\n",
        "\n",
        "        if mode == 'single':\n",
        "            batch_size, negative_sample_size = sample.size(0), 1\n",
        "\n",
        "            head = torch.index_select(\n",
        "                self.entity_embedding,\n",
        "                dim=0,\n",
        "                index=sample[:, 0]\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "            relation = torch.index_select(\n",
        "                self.relation_embedding,\n",
        "                dim=0,\n",
        "                index=sample[:, 1]\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "            tail = torch.index_select(\n",
        "                self.entity_embedding,\n",
        "                dim=0,\n",
        "                index=sample[:, 2]\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "        elif mode == 'head-batch':\n",
        "            tail_part, head_part = sample\n",
        "            batch_size, negative_sample_size = head_part.size(0), head_part.size(1)\n",
        "\n",
        "            head = torch.index_select(\n",
        "                self.entity_embedding,\n",
        "                dim=0,\n",
        "                index=head_part.view(-1)\n",
        "            ).view(batch_size, negative_sample_size, -1)\n",
        "\n",
        "            relation = torch.index_select(\n",
        "                self.relation_embedding,\n",
        "                dim=0,\n",
        "                index=tail_part[:, 1]\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "            tail = torch.index_select(\n",
        "                self.entity_embedding,\n",
        "                dim=0,\n",
        "                index=tail_part[:, 2]\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        elif mode == 'tail-batch':\n",
        "            head_part, tail_part = sample\n",
        "            batch_size, negative_sample_size = tail_part.size(0), tail_part.size(1)\n",
        "\n",
        "            head = torch.index_select(\n",
        "                self.entity_embedding,\n",
        "                dim=0,\n",
        "                index=head_part[:, 0]\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "            relation = torch.index_select(\n",
        "                self.relation_embedding,\n",
        "                dim=0,\n",
        "                index=head_part[:, 1]\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "            tail = torch.index_select(\n",
        "                self.entity_embedding,\n",
        "                dim=0,\n",
        "                index=tail_part.view(-1)\n",
        "            ).view(batch_size, negative_sample_size, -1)\n",
        "\n",
        "        else:\n",
        "            raise ValueError('mode %s not supported' % mode)\n",
        "\n",
        "        model_func = {\n",
        "            'TransE': self.TransE,\n",
        "            'DistMult': self.DistMult,\n",
        "            'ComplEx': self.ComplEx,\n",
        "            'RotatE': self.RotatE,\n",
        "            'pRotatE': self.pRotatE\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if self.model_name in model_func:\n",
        "            score = model_func[self.model_name](head, relation, tail, mode)\n",
        "        else:\n",
        "            raise ValueError('model %s not supported' % self.model_name)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def TransE(self, head, relation, tail, mode):\n",
        "        if mode == 'head-batch':\n",
        "            score = head + (relation - tail)\n",
        "        else:\n",
        "            score = (head + relation) - tail\n",
        "\n",
        "        score = self.gamma.item() - torch.norm(score, p=1, dim=2)\n",
        "        return score\n",
        "\n",
        "    def DistMult(self, head, relation, tail, mode):\n",
        "        if mode == 'head-batch':\n",
        "            score = head * (relation * tail)\n",
        "        else:\n",
        "            score = (head * relation) * tail\n",
        "\n",
        "        score = score.sum(dim=2)\n",
        "        return score\n",
        "\n",
        "    def ComplEx(self, head, relation, tail, mode):\n",
        "        re_head, im_head = torch.chunk(head, 2, dim=2)\n",
        "        re_relation, im_relation = torch.chunk(relation, 2, dim=2)\n",
        "        re_tail, im_tail = torch.chunk(tail, 2, dim=2)\n",
        "\n",
        "        if mode == 'head-batch':\n",
        "            re_score = re_relation * re_tail + im_relation * im_tail\n",
        "            im_score = re_relation * im_tail - im_relation * re_tail\n",
        "            score = re_head * re_score + im_head * im_score\n",
        "        else:\n",
        "            re_score = re_head * re_relation - im_head * im_relation\n",
        "            im_score = re_head * im_relation + im_head * re_relation\n",
        "            score = re_score * re_tail + im_score * im_tail\n",
        "\n",
        "        score = score.sum(dim=2)\n",
        "        return score\n",
        "\n",
        "    def RotatE(self, head, relation, tail, mode):\n",
        "        pi = 3.14159265358979323846\n",
        "\n",
        "        re_head, im_head = torch.chunk(head, 2, dim=2)\n",
        "        re_tail, im_tail = torch.chunk(tail, 2, dim=2)\n",
        "\n",
        "        # Make phases of relations uniformly distributed in [-pi, pi]\n",
        "\n",
        "        phase_relation = relation / (self.embedding_range.item() / pi)\n",
        "\n",
        "        re_relation = torch.cos(phase_relation)\n",
        "        im_relation = torch.sin(phase_relation)\n",
        "\n",
        "        if mode == 'head-batch':\n",
        "            re_score = re_relation * re_tail + im_relation * im_tail\n",
        "            im_score = re_relation * im_tail - im_relation * re_tail\n",
        "            re_score = re_score - re_head\n",
        "            im_score = im_score - im_head\n",
        "        else:\n",
        "            re_score = re_head * re_relation - im_head * im_relation\n",
        "            im_score = re_head * im_relation + im_head * re_relation\n",
        "            re_score = re_score - re_tail\n",
        "            im_score = im_score - im_tail\n",
        "\n",
        "        score = torch.stack([re_score, im_score], dim=0)\n",
        "        score = score.norm(dim=0)\n",
        "\n",
        "        score = self.gamma.item() - score.sum(dim=2)\n",
        "        return score\n",
        "\n",
        "    def pRotatE(self, head, relation, tail, mode):\n",
        "        pi = 3.14159262358979323846\n",
        "\n",
        "        # Make phases of entities and relations uniformly distributed in [-pi, pi]\n",
        "\n",
        "        phase_head = head / (self.embedding_range.item() / pi)\n",
        "        phase_relation = relation / (self.embedding_range.item() / pi)\n",
        "        phase_tail = tail / (self.embedding_range.item() / pi)\n",
        "\n",
        "        if mode == 'head-batch':\n",
        "            score = phase_head + (phase_relation - phase_tail)\n",
        "        else:\n",
        "            score = (phase_head + phase_relation) - phase_tail\n",
        "\n",
        "        score = torch.sin(score)\n",
        "        score = torch.abs(score)\n",
        "\n",
        "        score = self.gamma.item() - score.sum(dim=2) * self.modulus\n",
        "        return score\n",
        "\n",
        "    @staticmethod\n",
        "    def train_step(model, optimizer, train_iterator, train_rule_triple, args):\n",
        "        '''\n",
        "        A single train step. Apply back-propation and return the loss\n",
        "        '''\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        positive_sample, negative_sample, subsampling_weight, mode = next(train_iterator)\n",
        "\n",
        "        rule_triple, rule_p = next(train_rule_triple)\n",
        "\n",
        "        if args.cuda:\n",
        "            positive_sample = positive_sample.cuda()\n",
        "            negative_sample = negative_sample.cuda()\n",
        "            subsampling_weight = subsampling_weight.cuda()\n",
        "            rule_triple = rule_triple.cuda()\n",
        "            rule_p = rule_p.cuda()\n",
        "\n",
        "        negative_score = model((positive_sample, negative_sample), mode=mode)\n",
        "\n",
        "        if args.negative_adversarial_sampling:\n",
        "            # In self-adversarial sampling, we do not apply back-propagation on the sampling weight\n",
        "            negative_score = (F.softmax(negative_score * args.adversarial_temperature, dim=1).detach()\n",
        "                              * F.logsigmoid(-negative_score)).sum(dim=1)\n",
        "        else:\n",
        "            negative_score = F.logsigmoid(-negative_score).mean(dim=1)\n",
        "\n",
        "        positive_score = model(positive_sample)\n",
        "\n",
        "        rule_triple_score = model(rule_triple)\n",
        "\n",
        "        positive_score = F.logsigmoid(positive_score).squeeze(dim=1)\n",
        "\n",
        "        rule_triple_score = torch.sigmoid(rule_triple_score).squeeze(dim=1)\n",
        "\n",
        "        if args.uni_weight:\n",
        "            positive_sample_loss = - positive_score.mean()\n",
        "            negative_sample_loss = - negative_score.mean()\n",
        "        else:\n",
        "            positive_sample_loss = - (subsampling_weight * positive_score).sum() / subsampling_weight.sum()\n",
        "            negative_sample_loss = - (subsampling_weight * negative_score).sum() / subsampling_weight.sum()\n",
        "\n",
        "        loss = (positive_sample_loss + negative_sample_loss) / 2\n",
        "\n",
        "        if args.regularization != 0.0:\n",
        "            # Use L3 regularization\n",
        "            # regularization = args.regularization * (\n",
        "            #         model.entity_embedding.norm(p=3) ** 3 +\n",
        "            #         model.relation_embedding.norm(p=3).norm(p=3) ** 3\n",
        "            # )\n",
        "\n",
        "            # Use L2 regularization\n",
        "            regularization = args.regularization * (\n",
        "                    model.entity_embedding.norm(p=2) ** 2 / model.entity_embedding.size()[-1]\n",
        "                    + model.relation_embedding.norm(p=2).norm(p=2) ** 2 / model.relation_embedding.size()[-1]\n",
        "            )\n",
        "\n",
        "            loss = loss + regularization\n",
        "            regularization_log = {'regularization': regularization.item()}\n",
        "        else:\n",
        "            regularization_log = {}\n",
        "\n",
        "        if args.use_rule:\n",
        "            first = - ((rule_triple_score - 0.5) ** 2).mean()\n",
        "            last = (rule_triple_score.mean() - rule_p.mean()) ** 2\n",
        "            rule_confidence_loss = args.use_rule_coefficient * (0.25 - first + last)\n",
        "            loss = loss + rule_confidence_loss\n",
        "            rule_confidence_loss_log = {\n",
        "                'rule triple score:': str(rule_triple_score),\n",
        "                'rule triple score mean:': rule_triple_score.mean().item(),\n",
        "                'confidence loss first item': first.item(),\n",
        "                'confidence loss last item': last.item(),\n",
        "                'rule_confidence_loss': rule_confidence_loss.item(),\n",
        "            }\n",
        "        else:\n",
        "            rule_confidence_loss_log = {}\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if args.NNE:\n",
        "            for name, param in model.named_parameters():\n",
        "                if name == 'entity_embedding':\n",
        "                    param = torch.clamp(param, min=0.0, max=1.0)\n",
        "\n",
        "        log = {\n",
        "            **rule_confidence_loss_log,\n",
        "            **regularization_log,\n",
        "            'positive_sample_loss': positive_sample_loss.item(),\n",
        "            'negative_sample_loss': negative_sample_loss.item(),\n",
        "            'loss': loss.item()\n",
        "        }\n",
        "\n",
        "        return log\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def test_step(model, test_triples, all_true_triples, args, id2entity, id2relation):\n",
        "        '''\n",
        "        Evaluate the model on test or valid datasets\n",
        "        '''\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        if args.countries:\n",
        "            # Countries S* datasets are evaluated on AUC-PR\n",
        "            # Process test data for AUC-PR evaluation\n",
        "            sample = list()\n",
        "            y_true = list()\n",
        "            for head, relation, tail in test_triples:\n",
        "                for candidate_region in args.regions:\n",
        "                    y_true.append(1 if candidate_region == tail else 0)\n",
        "                    sample.append((head, relation, candidate_region))\n",
        "\n",
        "            sample = torch.LongTensor(sample)\n",
        "            if args.cuda:\n",
        "                sample = sample.cuda()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_score = model(sample).squeeze(1).cpu().numpy()\n",
        "\n",
        "            y_true = np.array(y_true)\n",
        "\n",
        "            # average_precision_score is the same as auc_pr\n",
        "            auc_pr = average_precision_score(y_true, y_score)\n",
        "\n",
        "            metrics = {'auc_pr': auc_pr}\n",
        "\n",
        "        else:\n",
        "            # Otherwise use standard (filtered) MRR, MR, HITS@1, HITS@3, and HITS@10 metrics\n",
        "            # Prepare dataloader for evaluation\n",
        "            test_dataloader_head = DataLoader(\n",
        "                TestDataset(\n",
        "                    test_triples,\n",
        "                    all_true_triples,\n",
        "                    args.nentity,\n",
        "                    args.nrelation,\n",
        "                    'head-batch'\n",
        "                ),\n",
        "                batch_size=args.test_batch_size,\n",
        "                num_workers=max(1, args.cpu_num // 2),\n",
        "                collate_fn=TestDataset.collate_fn\n",
        "            )\n",
        "\n",
        "            test_dataloader_tail = DataLoader(\n",
        "                TestDataset(\n",
        "                    test_triples,\n",
        "                    all_true_triples,\n",
        "                    args.nentity,\n",
        "                    args.nrelation,\n",
        "                    'tail-batch'\n",
        "                ),\n",
        "                batch_size=args.test_batch_size,\n",
        "                num_workers=max(1, args.cpu_num // 2),\n",
        "                collate_fn=TestDataset.collate_fn\n",
        "            )\n",
        "\n",
        "            test_dataset_list = [test_dataloader_head, test_dataloader_tail]\n",
        "\n",
        "            logs = []\n",
        "\n",
        "            step = 0\n",
        "            total_steps = sum([len(dataset) for dataset in test_dataset_list])\n",
        "\n",
        "            head_triple = []\n",
        "            tail_triple = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for test_dataset in test_dataset_list:\n",
        "                    for positive_sample, negative_sample, filter_bias, mode in test_dataset:\n",
        "                        if args.cuda:\n",
        "                            positive_sample = positive_sample.cuda()\n",
        "                            negative_sample = negative_sample.cuda()\n",
        "                            filter_bias = filter_bias.cuda()\n",
        "\n",
        "                        batch_size = positive_sample.size(0)\n",
        "\n",
        "                        score = model((positive_sample, negative_sample), mode)\n",
        "                        score += filter_bias\n",
        "\n",
        "#                         score = torch.clamp(score - args.margin, min=0.0)  # margin-based ranking loss\n",
        "\n",
        "                        # Explicitly sort all the entities to ensure that there is no test exposure bias\n",
        "                        argsort = torch.argsort(score, dim=1, descending=True)\n",
        "\n",
        "                        if mode == 'head-batch':\n",
        "                            positive_arg = positive_sample[:, 0]\n",
        "                        elif mode == 'tail-batch':\n",
        "                            positive_arg = positive_sample[:, 2]\n",
        "                        else:\n",
        "                            raise ValueError('mode %s not supported' % mode)\n",
        "\n",
        "                        for i in range(batch_size):\n",
        "                            # Notice that argsort is not ranking\n",
        "                            ranking = (argsort[i, :] == positive_arg[i]).nonzero()\n",
        "                            assert ranking.size(0) == 1\n",
        "\n",
        "                            # ranking + 1 is the true ranking used in evaluation metrics\n",
        "                            ranking = 1 + ranking.item()\n",
        "\n",
        "\n",
        "                            if ranking > 1:\n",
        "                                top10 = argsort[i, :][:10].tolist()\n",
        "                                top10_e = []\n",
        "                                for top in top10:\n",
        "                                    top10_e.append(id2entity[top])\n",
        "                                if mode == 'head-batch':\n",
        "                                    right = [id2entity[positive_sample[i][0].item()],\n",
        "                                             id2relation[positive_sample[i][1].item()],\n",
        "                                             id2entity[positive_sample[i][2].item()], int(ranking)]\n",
        "                                    tuple1 = right + top10_e\n",
        "                                    head_triple.append(tuple1)\n",
        "                                elif mode == 'tail-batch':\n",
        "                                    right = [id2entity[positive_sample[i][0].item()],\n",
        "                                             id2relation[positive_sample[i][1].item()],\n",
        "                                             id2entity[positive_sample[i][2].item()], int(ranking)]\n",
        "                                    tuple2 = right + top10_e\n",
        "                                    tail_triple.append(tuple2)\n",
        "\n",
        "                            logs.append({\n",
        "                                'MRR': 1.0 / ranking,\n",
        "                                'MR': float(ranking),\n",
        "                                'HITS@1': 1.0 if ranking <= 1 else 0.0,\n",
        "                                'HITS@3': 1.0 if ranking <= 3 else 0.0,\n",
        "                                'HITS@10': 1.0 if ranking <= 10 else 0.0,\n",
        "                            })\n",
        "\n",
        "                        if step % args.test_log_steps == 0:\n",
        "                            logging.critical('Evaluating the model... (%d/%d)' % (step, total_steps))\n",
        "\n",
        "                        step += 1\n",
        "\n",
        "            metrics = {}\n",
        "            for metric in logs[0].keys():\n",
        "                metrics[metric] = sum([log[metric] for log in logs]) / len(logs)\n",
        "\n",
        "        return metrics, head_triple, tail_triple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lzyaZ37PlLn"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luS_DaHOPlLo"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python3\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, triples, new_triple_only, nentity, nrelation, negative_sample_size, mode):\n",
        "        self.len = len(triples)\n",
        "        self.triples = triples\n",
        "        self.triples_and_new_triple = triples + new_triple_only\n",
        "        self.triple_set = set(triples)\n",
        "        self.nentity = nentity\n",
        "        self.nrelation = nrelation\n",
        "        self.negative_sample_size = negative_sample_size\n",
        "        self.mode = mode\n",
        "        self.count = self.count_frequency(triples)\n",
        "\n",
        "\n",
        "        self.true_head, self.true_tail = self.get_true_head_and_tail(self.triples_and_new_triple)\n",
        "        # self.true_head, self.true_tail = self.get_true_head_and_tail(self.triples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        positive_sample = self.triples[idx]\n",
        "\n",
        "        head, relation, tail = positive_sample\n",
        "\n",
        "        subsampling_weight = self.count[(head, relation)] + self.count[(tail, -relation-1)]\n",
        "        subsampling_weight = torch.sqrt(1 / torch.Tensor([subsampling_weight]))\n",
        "\n",
        "        negative_sample_list = []\n",
        "        negative_sample_size = 0\n",
        "\n",
        "        while negative_sample_size < self.negative_sample_size:\n",
        "            negative_sample = np.random.randint(self.nentity, size=self.negative_sample_size*2)\n",
        "            if self.mode == 'head-batch':\n",
        "                mask = np.in1d(\n",
        "                    negative_sample,\n",
        "                    self.true_head[(relation, tail)],\n",
        "                    assume_unique=True,\n",
        "                    invert=True\n",
        "                )\n",
        "            elif self.mode == 'tail-batch':\n",
        "                mask = np.in1d(\n",
        "                    negative_sample,\n",
        "                    self.true_tail[(head, relation)],\n",
        "                    assume_unique=True,\n",
        "                    invert=True\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError('Training batch mode %s not supported' % self.mode)\n",
        "            negative_sample = negative_sample[mask]\n",
        "            negative_sample_list.append(negative_sample)\n",
        "            negative_sample_size += negative_sample.size\n",
        "\n",
        "        negative_sample = np.concatenate(negative_sample_list)[:self.negative_sample_size]\n",
        "\n",
        "        negative_sample = torch.LongTensor(negative_sample)\n",
        "\n",
        "        positive_sample = torch.LongTensor(positive_sample)\n",
        "\n",
        "        return positive_sample, negative_sample, subsampling_weight, self.mode\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(data):\n",
        "        positive_sample = torch.stack([_[0] for _ in data], dim=0)\n",
        "        negative_sample = torch.stack([_[1] for _ in data], dim=0)\n",
        "        subsample_weight = torch.cat([_[2] for _ in data], dim=0)\n",
        "        mode = data[0][3]\n",
        "        return positive_sample, negative_sample, subsample_weight, mode\n",
        "\n",
        "    @staticmethod\n",
        "    def count_frequency(triples, start=4):\n",
        "        '''\n",
        "        Get frequency of a partial triple like (head, relation) or (relation, tail)\n",
        "        The frequency will be used for subsampling like word2vec\n",
        "        '''\n",
        "        count = {}\n",
        "        for head, relation, tail in triples:\n",
        "            if (head, relation) not in count:\n",
        "                count[(head, relation)] = start\n",
        "            else:\n",
        "                count[(head, relation)] += 1\n",
        "\n",
        "            if (tail, -relation-1) not in count:\n",
        "                count[(tail, -relation-1)] = start\n",
        "            else:\n",
        "                count[(tail, -relation-1)] += 1\n",
        "        return count\n",
        "\n",
        "    @staticmethod\n",
        "    def get_true_head_and_tail(triples):\n",
        "        '''\n",
        "        Build a dictionary of true triples that will\n",
        "        be used to filter these true triples for negative sampling\n",
        "        '''\n",
        "\n",
        "        true_head = {}\n",
        "        true_tail = {}\n",
        "\n",
        "        for head, relation, tail in triples:\n",
        "            if (head, relation) not in true_tail:\n",
        "                true_tail[(head, relation)] = []\n",
        "            true_tail[(head, relation)].append(tail)\n",
        "            if (relation, tail) not in true_head:\n",
        "                true_head[(relation, tail)] = []\n",
        "            true_head[(relation, tail)].append(head)\n",
        "\n",
        "        for relation, tail in true_head:\n",
        "            true_head[(relation, tail)] = np.array(list(set(true_head[(relation, tail)])))\n",
        "        for head, relation in true_tail:\n",
        "            true_tail[(head, relation)] = np.array(list(set(true_tail[(head, relation)])))\n",
        "\n",
        "        return true_head, true_tail\n",
        "\n",
        "\n",
        "class RuleTriple(Dataset):\n",
        "    def __init__(self, triples, nentity, nrelation):\n",
        "        self.len = len(triples)\n",
        "        self.triples = triples\n",
        "        self.nentity = nentity\n",
        "        self.nrelation = nrelation\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        head, relation, tail, p = self.triples[idx]\n",
        "        positive_sample = torch.LongTensor((head, relation, tail))\n",
        "        p = torch.FloatTensor((p,))\n",
        "\n",
        "        return positive_sample, p\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(data):\n",
        "        positive_sample = torch.stack([_[0] for _ in data], dim=0)\n",
        "        p = torch.stack([_[1] for _ in data], dim=0)\n",
        "        return positive_sample, p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, triples, all_true_triples, nentity, nrelation, mode):\n",
        "        self.len = len(triples)\n",
        "        self.triple_set = set(all_true_triples)\n",
        "        self.triples = triples\n",
        "        self.nentity = nentity\n",
        "        self.nrelation = nrelation\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        head, relation, tail = self.triples[idx]\n",
        "\n",
        "        if self.mode == 'head-batch':\n",
        "            tmp = [(0, rand_head) if (rand_head, relation, tail) not in self.triple_set\n",
        "                   else (-1, head) for rand_head in range(self.nentity)]\n",
        "            tmp[head] = (0, head)\n",
        "        elif self.mode == 'tail-batch':\n",
        "            tmp = [(0, rand_tail) if (head, relation, rand_tail) not in self.triple_set\n",
        "                   else (-1, tail) for rand_tail in range(self.nentity)]\n",
        "            tmp[tail] = (0, tail)\n",
        "        else:\n",
        "            raise ValueError('negative batch mode %s not supported' % self.mode)\n",
        "\n",
        "        tmp = torch.LongTensor(tmp)\n",
        "        filter_bias = tmp[:, 0].float()\n",
        "        negative_sample = tmp[:, 1]\n",
        "\n",
        "        positive_sample = torch.LongTensor((head, relation, tail))\n",
        "\n",
        "        return positive_sample, negative_sample, filter_bias, self.mode\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(data):\n",
        "        positive_sample = torch.stack([_[0] for _ in data], dim=0)\n",
        "        negative_sample = torch.stack([_[1] for _ in data], dim=0)\n",
        "        filter_bias = torch.stack([_[2] for _ in data], dim=0)\n",
        "        mode = data[0][3]\n",
        "        return positive_sample, negative_sample, filter_bias, mode\n",
        "\n",
        "class BidirectionalOneShotIterator(object):\n",
        "    def __init__(self, dataloader_head, dataloader_tail):\n",
        "        self.iterator_head = self.one_shot_iterator(dataloader_head)\n",
        "        self.iterator_tail = self.one_shot_iterator(dataloader_tail)\n",
        "        self.step = 0\n",
        "\n",
        "    def __next__(self):\n",
        "        self.step += 1\n",
        "        if self.step % 2 == 0:\n",
        "            data = next(self.iterator_head)\n",
        "        else:\n",
        "            data = next(self.iterator_tail)\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def one_shot_iterator(dataloader):\n",
        "        '''\n",
        "        Transform a PyTorch Dataloader into python iterator\n",
        "        '''\n",
        "        while True:\n",
        "            for data in dataloader:\n",
        "                yield data\n",
        "\n",
        "\n",
        "class Iterator(object):\n",
        "    def __init__(self, dataloader):\n",
        "        self.iterator = self.iterator(dataloader)\n",
        "        self.step = 0\n",
        "\n",
        "    def __next__(self):\n",
        "        self.step += 1\n",
        "        data = next(self.iterator)\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def iterator(dataloader):\n",
        "        '''\n",
        "        Transform a PyTorch Dataloader into python iterator\n",
        "        '''\n",
        "        while True:\n",
        "            for data in dataloader:\n",
        "                yield data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MScoyqbPlLr"
      },
      "source": [
        "Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwe8Q_gTPlLs",
        "outputId": "f5917bcf-f928-4333-d859-78da789bcdf5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:root:Model: RotatE\n",
            "2024-05-02 10:46:05,893 CRITICAL Model: RotatE\n",
            "CRITICAL:root:Data Path: /content/drive/MyDrive/Bachelor/FB15k\n",
            "2024-05-02 10:46:05,895 CRITICAL Data Path: /content/drive/MyDrive/Bachelor/FB15k\n",
            "CRITICAL:root:#entity: 14951\n",
            "2024-05-02 10:46:05,897 CRITICAL #entity: 14951\n",
            "CRITICAL:root:#relation: 1345\n",
            "2024-05-02 10:46:05,901 CRITICAL #relation: 1345\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model RotatE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:root:#train: 483142\n",
            "2024-05-02 10:46:08,149 CRITICAL #train: 483142\n",
            "CRITICAL:root:#valid: 50000\n",
            "2024-05-02 10:46:09,000 CRITICAL #valid: 50000\n",
            "CRITICAL:root:#test: 59071\n",
            "2024-05-02 10:46:10,179 CRITICAL #test: 59071\n",
            "CRITICAL:root:Model Parameter Configuration:\n",
            "2024-05-02 10:46:27,626 CRITICAL Model Parameter Configuration:\n",
            "CRITICAL:root:Parameter gamma: torch.Size([1]), require_grad = False\n",
            "2024-05-02 10:46:27,629 CRITICAL Parameter gamma: torch.Size([1]), require_grad = False\n",
            "CRITICAL:root:Parameter embedding_range: torch.Size([1]), require_grad = False\n",
            "2024-05-02 10:46:27,632 CRITICAL Parameter embedding_range: torch.Size([1]), require_grad = False\n",
            "CRITICAL:root:Parameter entity_embedding: torch.Size([14951, 2048]), require_grad = True\n",
            "2024-05-02 10:46:27,634 CRITICAL Parameter entity_embedding: torch.Size([14951, 2048]), require_grad = True\n",
            "CRITICAL:root:Parameter relation_embedding: torch.Size([1345, 1024]), require_grad = True\n",
            "2024-05-02 10:46:27,638 CRITICAL Parameter relation_embedding: torch.Size([1345, 1024]), require_grad = True\n",
            "CRITICAL:root:Ramdomly Initializing RotatE Model...\n",
            "2024-05-02 10:46:59,635 CRITICAL Ramdomly Initializing RotatE Model...\n",
            "CRITICAL:root:Start Training...\n",
            "2024-05-02 10:46:59,637 CRITICAL Start Training...\n",
            "CRITICAL:root:init_step = 0\n",
            "2024-05-02 10:46:59,638 CRITICAL init_step = 0\n",
            "CRITICAL:root:batch_size = 1024\n",
            "2024-05-02 10:46:59,640 CRITICAL batch_size = 1024\n",
            "CRITICAL:root:negative_adversarial_sampling = 1\n",
            "2024-05-02 10:46:59,642 CRITICAL negative_adversarial_sampling = 1\n",
            "CRITICAL:root:hidden_dim = 1024\n",
            "2024-05-02 10:46:59,645 CRITICAL hidden_dim = 1024\n",
            "CRITICAL:root:gamma = 24.000000\n",
            "2024-05-02 10:46:59,647 CRITICAL gamma = 24.000000\n",
            "CRITICAL:root:negative_adversarial_sampling = True\n",
            "2024-05-02 10:46:59,649 CRITICAL negative_adversarial_sampling = True\n",
            "CRITICAL:root:rule_num = 1580\n",
            "2024-05-02 10:46:59,651 CRITICAL rule_num = 1580\n",
            "CRITICAL:root:new_triple_num = 12512672\n",
            "2024-05-02 10:46:59,653 CRITICAL new_triple_num = 12512672\n",
            "CRITICAL:root:adversarial_temperature = 1.000000\n",
            "2024-05-02 10:46:59,663 CRITICAL adversarial_temperature = 1.000000\n",
            "CRITICAL:root:learning_rate = 0.000100\n",
            "2024-05-02 10:46:59,665 CRITICAL learning_rate = 0.000100\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My variable list:  {'step': 0, 'current_learning_rate': 0.0001, 'warm_up_steps': 7500}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:root:Training average rule triple score mean: at step 0: 0.054947\n",
            "2024-05-02 10:47:42,197 CRITICAL Training average rule triple score mean: at step 0: 0.054947\n",
            "CRITICAL:root:Training average confidence loss first item at step 0: -0.200956\n",
            "2024-05-02 10:47:42,199 CRITICAL Training average confidence loss first item at step 0: -0.200956\n",
            "CRITICAL:root:Training average confidence loss last item at step 0: 0.611343\n",
            "2024-05-02 10:47:42,201 CRITICAL Training average confidence loss last item at step 0: 0.611343\n",
            "CRITICAL:root:Training average rule_confidence_loss at step 0: 0.212460\n",
            "2024-05-02 10:47:42,203 CRITICAL Training average rule_confidence_loss at step 0: 0.212460\n",
            "CRITICAL:root:Training average regularization at step 0: 0.700432\n",
            "2024-05-02 10:47:42,204 CRITICAL Training average regularization at step 0: 0.700432\n",
            "CRITICAL:root:Training average positive_sample_loss at step 0: 3.150938\n",
            "2024-05-02 10:47:42,206 CRITICAL Training average positive_sample_loss at step 0: 3.150938\n",
            "CRITICAL:root:Training average negative_sample_loss at step 0: 0.053282\n",
            "2024-05-02 10:47:42,207 CRITICAL Training average negative_sample_loss at step 0: 0.053282\n",
            "CRITICAL:root:Training average loss at step 0: 2.515002\n",
            "2024-05-02 10:47:42,209 CRITICAL Training average loss at step 0: 2.515002\n",
            "CRITICAL:root:Training average rule triple score: at step 0: \n",
            " tensor([0.0499, 0.0260, 0.0346, 0.0609, 0.0381, 0.0448, 0.0573, 0.0503, 0.0331,\n",
            "        0.0570, 0.3448, 0.0561, 0.0303, 0.0531, 0.0411, 0.0355, 0.0736, 0.0429,\n",
            "        0.0541, 0.0720, 0.0538, 0.0355, 0.0513, 0.0225, 0.0302, 0.0323, 0.0440,\n",
            "        0.0243, 0.0452, 0.0700, 0.0452, 0.0487], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "2024-05-02 10:47:42,210 CRITICAL Training average rule triple score: at step 0: \n",
            " tensor([0.0499, 0.0260, 0.0346, 0.0609, 0.0381, 0.0448, 0.0573, 0.0503, 0.0331,\n",
            "        0.0570, 0.3448, 0.0561, 0.0303, 0.0531, 0.0411, 0.0355, 0.0736, 0.0429,\n",
            "        0.0541, 0.0720, 0.0538, 0.0355, 0.0513, 0.0225, 0.0302, 0.0323, 0.0440,\n",
            "        0.0243, 0.0452, 0.0700, 0.0452, 0.0487], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "CRITICAL:root:Training average rule triple score mean: at step 100: 0.319923\n",
            "2024-05-02 12:05:46,447 CRITICAL Training average rule triple score mean: at step 100: 0.319923\n",
            "CRITICAL:root:Training average confidence loss first item at step 100: -0.063685\n",
            "2024-05-02 12:05:46,450 CRITICAL Training average confidence loss first item at step 100: -0.063685\n",
            "CRITICAL:root:Training average confidence loss last item at step 100: 0.286465\n",
            "2024-05-02 12:05:46,452 CRITICAL Training average confidence loss last item at step 100: 0.286465\n",
            "CRITICAL:root:Training average rule_confidence_loss at step 100: 0.120030\n",
            "2024-05-02 12:05:46,455 CRITICAL Training average rule_confidence_loss at step 100: 0.120030\n",
            "CRITICAL:root:Training average regularization at step 100: 0.598053\n",
            "2024-05-02 12:05:46,457 CRITICAL Training average regularization at step 100: 0.598053\n",
            "CRITICAL:root:Training average positive_sample_loss at step 100: 1.246925\n",
            "2024-05-02 12:05:46,459 CRITICAL Training average positive_sample_loss at step 100: 1.246925\n",
            "CRITICAL:root:Training average negative_sample_loss at step 100: 0.469256\n",
            "2024-05-02 12:05:46,463 CRITICAL Training average negative_sample_loss at step 100: 0.469256\n",
            "CRITICAL:root:Training average loss at step 100: 1.576174\n",
            "2024-05-02 12:05:46,465 CRITICAL Training average loss at step 100: 1.576174\n",
            "CRITICAL:root:Training average rule triple score mean: at step 200: 0.453343\n",
            "2024-05-02 12:06:13,244 CRITICAL Training average rule triple score mean: at step 200: 0.453343\n",
            "CRITICAL:root:Training average confidence loss first item at step 200: -0.041746\n",
            "2024-05-02 12:06:13,246 CRITICAL Training average confidence loss first item at step 200: -0.041746\n",
            "CRITICAL:root:Training average confidence loss last item at step 200: 0.174125\n",
            "2024-05-02 12:06:13,248 CRITICAL Training average confidence loss last item at step 200: 0.174125\n",
            "CRITICAL:root:Training average rule_confidence_loss at step 200: 0.093174\n",
            "2024-05-02 12:06:13,252 CRITICAL Training average rule_confidence_loss at step 200: 0.093174\n",
            "CRITICAL:root:Training average regularization at step 200: 0.576053\n",
            "2024-05-02 12:06:13,254 CRITICAL Training average regularization at step 200: 0.576053\n",
            "CRITICAL:root:Training average positive_sample_loss at step 200: 0.928668\n",
            "2024-05-02 12:06:13,256 CRITICAL Training average positive_sample_loss at step 200: 0.928668\n",
            "CRITICAL:root:Training average negative_sample_loss at step 200: 0.634410\n",
            "2024-05-02 12:06:13,257 CRITICAL Training average negative_sample_loss at step 200: 0.634410\n",
            "CRITICAL:root:Training average loss at step 200: 1.450766\n",
            "2024-05-02 12:06:13,261 CRITICAL Training average loss at step 200: 1.450766\n",
            "CRITICAL:root:Evaluating on Valid Dataset...\n",
            "2024-05-02 12:06:13,263 CRITICAL Evaluating on Valid Dataset...\n",
            "CRITICAL:root:Evaluating the model... (0/6250)\n",
            "2024-05-02 12:06:14,744 CRITICAL Evaluating the model... (0/6250)\n",
            "CRITICAL:root:Evaluating the model... (200/6250)\n",
            "2024-05-02 12:06:31,359 CRITICAL Evaluating the model... (200/6250)\n",
            "CRITICAL:root:Evaluating the model... (400/6250)\n",
            "2024-05-02 12:06:47,766 CRITICAL Evaluating the model... (400/6250)\n",
            "CRITICAL:root:Evaluating the model... (600/6250)\n",
            "2024-05-02 12:07:04,233 CRITICAL Evaluating the model... (600/6250)\n",
            "CRITICAL:root:Evaluating the model... (800/6250)\n",
            "2024-05-02 12:07:20,683 CRITICAL Evaluating the model... (800/6250)\n",
            "CRITICAL:root:Evaluating the model... (1000/6250)\n",
            "2024-05-02 12:07:37,112 CRITICAL Evaluating the model... (1000/6250)\n",
            "CRITICAL:root:Evaluating the model... (1200/6250)\n",
            "2024-05-02 12:07:53,523 CRITICAL Evaluating the model... (1200/6250)\n",
            "CRITICAL:root:Evaluating the model... (1400/6250)\n",
            "2024-05-02 12:08:09,942 CRITICAL Evaluating the model... (1400/6250)\n",
            "CRITICAL:root:Evaluating the model... (1600/6250)\n",
            "2024-05-02 12:08:26,378 CRITICAL Evaluating the model... (1600/6250)\n",
            "CRITICAL:root:Evaluating the model... (1800/6250)\n",
            "2024-05-02 12:08:42,811 CRITICAL Evaluating the model... (1800/6250)\n",
            "CRITICAL:root:Evaluating the model... (2000/6250)\n",
            "2024-05-02 12:08:59,240 CRITICAL Evaluating the model... (2000/6250)\n",
            "CRITICAL:root:Evaluating the model... (2200/6250)\n",
            "2024-05-02 12:09:15,686 CRITICAL Evaluating the model... (2200/6250)\n",
            "CRITICAL:root:Evaluating the model... (2400/6250)\n",
            "2024-05-02 12:09:32,108 CRITICAL Evaluating the model... (2400/6250)\n",
            "CRITICAL:root:Evaluating the model... (2600/6250)\n",
            "2024-05-02 12:09:48,543 CRITICAL Evaluating the model... (2600/6250)\n",
            "CRITICAL:root:Evaluating the model... (2800/6250)\n",
            "2024-05-02 12:10:04,982 CRITICAL Evaluating the model... (2800/6250)\n",
            "CRITICAL:root:Evaluating the model... (3000/6250)\n",
            "2024-05-02 12:10:21,419 CRITICAL Evaluating the model... (3000/6250)\n",
            "CRITICAL:root:Evaluating the model... (3200/6250)\n",
            "2024-05-02 12:10:38,778 CRITICAL Evaluating the model... (3200/6250)\n",
            "CRITICAL:root:Evaluating the model... (3400/6250)\n",
            "2024-05-02 12:10:55,220 CRITICAL Evaluating the model... (3400/6250)\n",
            "CRITICAL:root:Evaluating the model... (3600/6250)\n",
            "2024-05-02 12:11:11,668 CRITICAL Evaluating the model... (3600/6250)\n",
            "CRITICAL:root:Evaluating the model... (3800/6250)\n",
            "2024-05-02 12:11:28,072 CRITICAL Evaluating the model... (3800/6250)\n",
            "CRITICAL:root:Evaluating the model... (4000/6250)\n",
            "2024-05-02 12:11:44,520 CRITICAL Evaluating the model... (4000/6250)\n",
            "CRITICAL:root:Evaluating the model... (4200/6250)\n",
            "2024-05-02 12:12:00,958 CRITICAL Evaluating the model... (4200/6250)\n",
            "CRITICAL:root:Evaluating the model... (4400/6250)\n",
            "2024-05-02 12:12:17,415 CRITICAL Evaluating the model... (4400/6250)\n",
            "CRITICAL:root:Evaluating the model... (4600/6250)\n",
            "2024-05-02 12:12:33,897 CRITICAL Evaluating the model... (4600/6250)\n",
            "CRITICAL:root:Evaluating the model... (4800/6250)\n",
            "2024-05-02 12:12:50,333 CRITICAL Evaluating the model... (4800/6250)\n",
            "CRITICAL:root:Evaluating the model... (5000/6250)\n",
            "2024-05-02 12:13:06,763 CRITICAL Evaluating the model... (5000/6250)\n",
            "CRITICAL:root:Evaluating the model... (5200/6250)\n",
            "2024-05-02 12:13:23,170 CRITICAL Evaluating the model... (5200/6250)\n",
            "CRITICAL:root:Evaluating the model... (5400/6250)\n",
            "2024-05-02 12:13:39,583 CRITICAL Evaluating the model... (5400/6250)\n",
            "CRITICAL:root:Evaluating the model... (5600/6250)\n",
            "2024-05-02 12:13:56,013 CRITICAL Evaluating the model... (5600/6250)\n",
            "CRITICAL:root:Evaluating the model... (5800/6250)\n",
            "2024-05-02 12:14:12,421 CRITICAL Evaluating the model... (5800/6250)\n",
            "CRITICAL:root:Evaluating the model... (6000/6250)\n",
            "2024-05-02 12:14:28,835 CRITICAL Evaluating the model... (6000/6250)\n",
            "CRITICAL:root:Evaluating the model... (6200/6250)\n",
            "2024-05-02 12:14:45,248 CRITICAL Evaluating the model... (6200/6250)\n",
            "CRITICAL:root:Valid MRR at step 200: 0.006942\n",
            "2024-05-02 12:14:49,536 CRITICAL Valid MRR at step 200: 0.006942\n",
            "CRITICAL:root:Valid MR at step 200: 4784.176670\n",
            "2024-05-02 12:14:49,539 CRITICAL Valid MR at step 200: 4784.176670\n",
            "CRITICAL:root:Valid HITS@1 at step 200: 0.004620\n",
            "2024-05-02 12:14:49,540 CRITICAL Valid HITS@1 at step 200: 0.004620\n",
            "CRITICAL:root:Valid HITS@3 at step 200: 0.005680\n",
            "2024-05-02 12:14:49,542 CRITICAL Valid HITS@3 at step 200: 0.005680\n",
            "CRITICAL:root:Valid HITS@10 at step 200: 0.008800\n",
            "2024-05-02 12:14:49,546 CRITICAL Valid HITS@10 at step 200: 0.008800\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'MRR': 0.006941663437831674, 'MR': 4784.17667, 'HITS@1': 0.00462, 'HITS@3': 0.00568, 'HITS@10': 0.0088}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:root:Training average rule triple score mean: at step 300: 0.500311\n",
            "2024-05-02 12:15:16,300 CRITICAL Training average rule triple score mean: at step 300: 0.500311\n",
            "CRITICAL:root:Training average confidence loss first item at step 300: -0.034245\n",
            "2024-05-02 12:15:16,302 CRITICAL Training average confidence loss first item at step 300: -0.034245\n",
            "CRITICAL:root:Training average confidence loss last item at step 300: 0.135566\n",
            "2024-05-02 12:15:16,304 CRITICAL Training average confidence loss last item at step 300: 0.135566\n",
            "CRITICAL:root:Training average rule_confidence_loss at step 300: 0.083962\n",
            "2024-05-02 12:15:16,306 CRITICAL Training average rule_confidence_loss at step 300: 0.083962\n",
            "CRITICAL:root:Training average regularization at step 300: 0.567137\n",
            "2024-05-02 12:15:16,309 CRITICAL Training average regularization at step 300: 0.567137\n",
            "CRITICAL:root:Training average positive_sample_loss at step 300: 0.812415\n",
            "2024-05-02 12:15:16,312 CRITICAL Training average positive_sample_loss at step 300: 0.812415\n",
            "CRITICAL:root:Training average negative_sample_loss at step 300: 0.690755\n",
            "2024-05-02 12:15:16,314 CRITICAL Training average negative_sample_loss at step 300: 0.690755\n",
            "CRITICAL:root:Training average loss at step 300: 1.402684\n",
            "2024-05-02 12:15:16,317 CRITICAL Training average loss at step 300: 1.402684\n",
            "CRITICAL:root:Training average rule triple score mean: at step 400: 0.522718\n",
            "2024-05-02 12:15:43,070 CRITICAL Training average rule triple score mean: at step 400: 0.522718\n",
            "CRITICAL:root:Training average confidence loss first item at step 400: -0.030555\n",
            "2024-05-02 12:15:43,072 CRITICAL Training average confidence loss first item at step 400: -0.030555\n",
            "CRITICAL:root:Training average confidence loss last item at step 400: 0.116930\n",
            "2024-05-02 12:15:43,074 CRITICAL Training average confidence loss last item at step 400: 0.116930\n",
            "CRITICAL:root:Training average rule_confidence_loss at step 400: 0.079497\n",
            "2024-05-02 12:15:43,076 CRITICAL Training average rule_confidence_loss at step 400: 0.079497\n",
            "CRITICAL:root:Training average regularization at step 400: 0.562524\n",
            "2024-05-02 12:15:43,082 CRITICAL Training average regularization at step 400: 0.562524\n",
            "CRITICAL:root:Training average positive_sample_loss at step 400: 0.749711\n",
            "2024-05-02 12:15:43,084 CRITICAL Training average positive_sample_loss at step 400: 0.749711\n",
            "CRITICAL:root:Training average negative_sample_loss at step 400: 0.715685\n",
            "2024-05-02 12:15:43,086 CRITICAL Training average negative_sample_loss at step 400: 0.715685\n",
            "CRITICAL:root:Training average loss at step 400: 1.374719\n",
            "2024-05-02 12:15:43,087 CRITICAL Training average loss at step 400: 1.374719\n",
            "CRITICAL:root:Evaluating on Valid Dataset...\n",
            "2024-05-02 12:15:43,088 CRITICAL Evaluating on Valid Dataset...\n",
            "CRITICAL:root:Evaluating the model... (0/6250)\n",
            "2024-05-02 12:15:44,242 CRITICAL Evaluating the model... (0/6250)\n",
            "CRITICAL:root:Evaluating the model... (200/6250)\n",
            "2024-05-02 12:16:00,792 CRITICAL Evaluating the model... (200/6250)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # arguments setting\n",
        "\n",
        "\n",
        "\n",
        "    i = 0\n",
        "    new_conclusions = []\n",
        "    # m_n_s(args, tsv_source_path=args.row_triples, amie_path=args.amie_plus_path, minhc=args.minhc, minc=args.minc, minpca=args.minpca)\n",
        "    # preprocess()\n",
        "    # rule_reasoning(args)\n",
        "    runKGE(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVwqflj3PlLt"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/Bachelor/Results/checkpoint')\n",
        "\n",
        "# # Iterate over the items in the checkpoint dictionary\n",
        "# for key, value in checkpoint.items():\n",
        "#     print(f\"Key: {key}\")\n",
        "#     print(f\"Type: {type(value)}\")\n",
        "#     print(f\"Value: {value}\")\n",
        "#     print(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4864095,
          "sourceId": 8208447,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4864110,
          "sourceId": 8208464,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}